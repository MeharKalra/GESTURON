{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyelbc1sQ+BCAxroBj2cEq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeharKalra/GESTURON/blob/main/Gesturon_Experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "CypXcB7tnpk1"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_dict = {\"Non-gesture\":0, 'Pointing with one finger':1,'Pointing with two fingers':2,'Throw up':3,'Throw down':4,\n",
        "              'Throw left':5,'Throw right':6,'Open twice':7,'Zoom in':8,'Zoom out':9}"
      ],
      "metadata": {
        "id": "O2IafRm9oPJL"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw_path = \"/train_flow_vector.csv\"\n",
        "train_label_path = \"/Labels.csv\"\n",
        "test_raw_path = \"/test_flow_vector.csv\"\n",
        "test_label_path = \"/Labels (1).csv\"\n",
        "\n",
        "train_traj_path = \"/temporal_diff_traj.csv\"\n",
        "test_traj_path = \"/temporal_diff_traj_test.csv\"\n"
      ],
      "metadata": {
        "id": "_q6F8fC1zMOQ"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ProcessData(df,label_df):\n",
        "  for index,row in label_df.iterrows():\n",
        "    Label = row[\"Label\"]\n",
        "    if Label == \"Double click with one finger\":\n",
        "      df.drop(index,inplace=True)\n",
        "      label_df.drop(index,inplace=True)\n",
        "    elif Label == \"Double click with two fingers\":\n",
        "      df.drop(index,inplace=True)\n",
        "      label_df.drop(index,inplace=True)\n",
        "    elif Label == \"Click with one finger\":\n",
        "      df.drop(index,inplace=True)\n",
        "      label_df.drop(index,inplace=True)\n",
        "    elif Label == \"Click with two fingers\":\n",
        "      df.drop(index,inplace=True)\n",
        "      label_df.drop(index,inplace=True)"
      ],
      "metadata": {
        "id": "76TEjFlbxrN0"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ProcessDataNew(data):\n",
        "  for index,row in data.iterrows():\n",
        "      Label = row[\"label\"]\n",
        "      if Label == \"Double click with one finger\":\n",
        "        data.drop(index,inplace=True)\n",
        "      elif Label == \"Double click with two fingers\":\n",
        "        data.drop(index,inplace=True)\n",
        "      elif Label == \"Click with one finger\":\n",
        "        data.drop(index,inplace=True)\n",
        "      elif Label == \"Click with two fingers\":\n",
        "        data.drop(index,inplace=True)\n"
      ],
      "metadata": {
        "id": "vwEDL65-s2Wf"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MakeData(path_list,Raw=True,scale=False,reduced=False):\n",
        "  if Raw:\n",
        "    train_X = pd.read_csv(path_list[0])\n",
        "    train_Y = pd.read_csv(path_list[1])\n",
        "    test_X = pd.read_csv(path_list[2])\n",
        "    test_Y = pd.read_csv(path_list[3])\n",
        "\n",
        "    ProcessData(train_X,train_Y)\n",
        "    ProcessData(test_X,test_Y)\n",
        "\n",
        "  else:\n",
        "    train_data = pd.read_csv(path_list[0])\n",
        "    test_data = pd.read_csv(path_list[1])\n",
        "    ProcessDataNew(train_data)\n",
        "    ProcessDataNew(test_data)\n",
        "    train_X = train_data.drop(\"label\",axis=1)\n",
        "    train_Y = pd.DataFrame(train_data[\"label\"])\n",
        "    test_X = test_data.drop(\"label\",axis=1)\n",
        "    test_Y = pd.DataFrame(test_data[\"label\"])\n",
        "\n",
        "  if scale:\n",
        "    scaler = StandardScaler()\n",
        "    train_X = scaler.fit_transform(train_X)\n",
        "    test_X = scaler.transform(test_X)\n",
        "\n",
        "  if reduced:\n",
        "    pca = PCA(n_components=0.95)  # Retain 95% variance\n",
        "    train_X = pca.fit_transform(train_X)\n",
        "    test_X = pca.transform(test_X)\n",
        "\n",
        "  return train_X,train_Y,test_X,test_Y\n"
      ],
      "metadata": {
        "id": "N6lklRW4tXxq"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM CLASSIFIER EXPERIEMNT"
      ],
      "metadata": {
        "id": "1AiXL10KnQuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def SVM(train_X,test_X,train_Y,test_Y,C):\n",
        "  train_Y = train_Y.values.ravel()\n",
        "  test_Y = test_Y.values.ravel()\n",
        "  print(\"Parmeter C: \",C)\n",
        "  svm_classifier = SVC(kernel='rbf', random_state=42, C=C)\n",
        "  svm_classifier.fit(train_X, train_Y)\n",
        "\n",
        "  y_pred_train = svm_classifier.predict(train_X)\n",
        "  accuracy = accuracy_score(train_Y, y_pred_train)\n",
        "  print(f\"Accuracy of the SVM classifier on Training set: {accuracy:.2f}\")\n",
        "\n",
        "  y_pred_test = svm_classifier.predict(test_X)\n",
        "  accuracy = accuracy_score(test_Y, y_pred_test)\n",
        "  print(f\"Accuracy of the classifier on Testing set: {accuracy:.2f}\")\n",
        "  print(\"classification Report\")\n",
        "  print(classification_report(test_Y, y_pred_test,target_names=list(class_dict.keys())))\n",
        "\n",
        "  #return y_pred_train,y_pred_test"
      ],
      "metadata": {
        "id": "gfdTfb_1nzp_"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NEURAL NETWORK EXPERIMENT"
      ],
      "metadata": {
        "id": "X1FISrAKneaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "I9-JCLBapeBt"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def NeuralNetwork(train_X,test_X,train_Y,test_Y,learning_rate,n_input,reduced=False):\n",
        "  encoder = OneHotEncoder(sparse_output=False)\n",
        "  train_Y_onehot = encoder.fit_transform(train_Y)\n",
        "  test_Y_onehot = encoder.transform(test_Y)\n",
        "\n",
        "  if reduced:\n",
        "    model = Sequential([\n",
        "      Dense(128, activation='relu', input_shape=(n_input,)),  # First hidden layer\n",
        "      Dropout(0.3),                                     # Dropout for regularization\n",
        "      Dense(64, activation='relu'),                      # Second hidden layer\n",
        "      Dropout(0.3),                                        # Dropout for regularization\n",
        "      Dense(10, activation='softmax')  ])                  # Output layer for 10 classes\n",
        "  else:\n",
        "      model = Sequential([\n",
        "      Dense(256, activation='relu', input_shape=(n_input,)),  # First hidden layer\n",
        "      Dropout(0.3),                                     # Dropout for regularization\n",
        "      Dense(128, activation='relu'),                      # Second hidden layer\n",
        "      Dropout(0.3),                                        # Dropout for regularization\n",
        "      Dense(10, activation='softmax')                     # Output layer for 10 classes\n",
        "    ])\n",
        "\n",
        "  # Compile the model with Adam optimizer and categorical crossentropy\n",
        "  model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  # Early stopping to prevent overfitting\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "  # Train the model\n",
        "  model.fit(train_X, train_Y_onehot, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
        "\n",
        "  # Evaluate the model on the test set\n",
        "  train_loss, train_accuracy = model.evaluate(train_X, train_Y_onehot, verbose=0)\n",
        "  print(f\"Train Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "  test_loss, test_accuracy = model.evaluate(test_X,test_Y_onehot, verbose=0)\n",
        "  print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F5YKoSE4y_95"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment"
      ],
      "metadata": {
        "id": "EEA971zRztZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "def make_repoert():\n",
        "  #Make Raw data\n",
        "  print(\"Without trajectory features\")\n",
        "  path_list = [train_raw_path,train_label_path,test_raw_path,test_label_path]\n",
        "  print(\"Un-processed Data :\")\n",
        "  train_X,train_Y,test_X,test_Y = MakeData(path_list,Raw=True,scale=False,reduced=False)\n",
        "  print(\"Number of features :\",train_X.shape[1])\n",
        "  print(\"SVM\")\n",
        "  C = [1,10]\n",
        "  for c in C:\n",
        "    SVM(train_X,test_X,train_Y,test_Y,c)\n",
        "\n",
        "  print(\"Neural Network\")\n",
        "  learning_rate = [0.001,0.0001]\n",
        "  n_input = train_X.shape[1]\n",
        "  for lr in learning_rate:\n",
        "    print(\"Learning Rate :\",lr)\n",
        "    NeuralNetwork(train_X,test_X,train_Y,test_Y,lr,n_input,reduced=False)\n",
        "\n",
        "  print(\"Scaled Data\")\n",
        "  train_X,train_Y,test_X,test_Y = MakeData(path_list,Raw=True,scale=True,reduced= False)\n",
        "  print(\"Number of features :\",train_X.shape[1])\n",
        "\n",
        "  print(\"SVM\")\n",
        "  C = [1,10]\n",
        "  for c in C:\n",
        "    SVM(train_X,test_X,train_Y,test_Y,c)\n",
        "\n",
        "  print(\"Neural Network\")\n",
        "  learning_rate = [0.001,0.0001]\n",
        "  n_input = train_X.shape[1]\n",
        "  for lr in learning_rate:\n",
        "    print(\"Learning Rate :\",lr)\n",
        "    NeuralNetwork(train_X,test_X,train_Y,test_Y,lr,n_input,reduced=False)\n",
        "\n",
        "  print(\"PCA Data\")\n",
        "  train_X,train_Y,test_X,test_Y = MakeData(path_list,Raw=True,scale=True,reduced=True)\n",
        "  print(\"Number of features :\",train_X.shape[1])\n",
        "\n",
        "  print(\"SVM\")\n",
        "  C = [1,10]\n",
        "  for c in C:\n",
        "    SVM(train_X,test_X,train_Y,test_Y,c)\n",
        "\n",
        "  print(\"Neural Network\")\n",
        "  learning_rate = [0.001,0.0001]\n",
        "  n_input = train_X.shape[1]\n",
        "  for lr in learning_rate:\n",
        "    print(\"Learning Rate :\",lr)\n",
        "    NeuralNetwork(train_X,test_X,train_Y,test_Y,lr,n_input,reduced=True)\n",
        "\n",
        "  print(\"With trajectory features\")\n",
        "  path_list = [train_traj_path,test_traj_path]\n",
        "\n",
        "  train_X,train_Y,test_X,test_Y = MakeData(path_list,Raw=False,scale=False,reduced=False)\n",
        "  print(\"Number of features :\",train_X.shape[1])\n",
        "  print(\"SVM\")\n",
        "  C = [1,10]\n",
        "  for c in C:\n",
        "    SVM(train_X,test_X,train_Y,test_Y,c)\n",
        "\n",
        "  print(\"Neural Network\")\n",
        "  learning_rate = [0.001,0.0001]\n",
        "  n_input = train_X.shape[1]\n",
        "  for lr in learning_rate:\n",
        "    print(\"Learning Rate :\",lr)\n",
        "    NeuralNetwork(train_X,test_X,train_Y,test_Y,lr,n_input,reduced=False)\n",
        "\n",
        "  print(\"Scaled Data\")\n",
        "  train_X,train_Y,test_X,test_Y = MakeData(path_list,Raw=False,scale=True,reduced= False)\n",
        "  print(\"Number of features :\",train_X.shape[1])\n",
        "\n",
        "  print(\"SVM\")\n",
        "  C = [1,10]\n",
        "  for c in C:\n",
        "    SVM(train_X,test_X,train_Y,test_Y,c)\n",
        "\n",
        "  print(\"Neural Network\")\n",
        "  learning_rate = [0.001,0.0001]\n",
        "  n_input = train_X.shape[1]\n",
        "  for lr in learning_rate:\n",
        "    print(\"Learning Rate :\",lr)\n",
        "    NeuralNetwork(train_X,test_X,train_Y,test_Y,lr,n_input,reduced=False)\n",
        "\n",
        "  print(\"PCA Data\")\n",
        "  train_X,train_Y,test_X,test_Y = MakeData(path_list,Raw=False,scale=True,reduced=True)\n",
        "  print(\"Number of features :\",train_X.shape[1])\n",
        "\n",
        "  print(\"SVM\")\n",
        "  C = [1,10]\n",
        "  for c in C:\n",
        "    SVM(train_X,test_X,train_Y,test_Y,c)\n",
        "\n",
        "  print(\"Neural Network\")\n",
        "  learning_rate = [0.001,0.0001]\n",
        "  n_input = train_X.shape[1]\n",
        "  for lr in learning_rate:\n",
        "    print(\"Learning Rate :\",lr)\n",
        "    NeuralNetwork(train_X,test_X,train_Y,test_Y,lr,n_input,reduced=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zFQp9xjSzwLh"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_repoert()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N6jcmu--DmN",
        "outputId": "3cb3d786-fc0d-4811-b163-6f63b82d24bd"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without trajectory features\n",
            "Un-processed Data :\n",
            "Number of features : 3087\n",
            "SVM\n",
            "Parmeter C:  1\n",
            "Accuracy of the SVM classifier on Training set: 0.80\n",
            "Accuracy of the classifier on Testing set: 0.63\n",
            "classification Report\n",
            "                           precision    recall  f1-score   support\n",
            "\n",
            "              Non-gesture       0.47      0.69      0.56        81\n",
            " Pointing with one finger       0.86      0.63      0.73        51\n",
            "Pointing with two fingers       0.41      0.35      0.38        49\n",
            "                 Throw up       0.43      0.57      0.49        51\n",
            "               Throw down       0.90      0.75      0.82        51\n",
            "               Throw left       0.82      0.65      0.73        51\n",
            "              Throw right       0.82      0.71      0.76        52\n",
            "               Open twice       0.76      0.75      0.75        51\n",
            "                  Zoom in       0.67      0.66      0.67        50\n",
            "                 Zoom out       0.53      0.51      0.52        49\n",
            "\n",
            "                 accuracy                           0.63       536\n",
            "                macro avg       0.67      0.63      0.64       536\n",
            "             weighted avg       0.66      0.63      0.64       536\n",
            "\n",
            "Parmeter C:  10\n",
            "Accuracy of the SVM classifier on Training set: 0.96\n",
            "Accuracy of the classifier on Testing set: 0.67\n",
            "classification Report\n",
            "                           precision    recall  f1-score   support\n",
            "\n",
            "              Non-gesture       0.54      0.72      0.62        81\n",
            " Pointing with one finger       0.84      0.63      0.72        51\n",
            "Pointing with two fingers       0.49      0.39      0.43        49\n",
            "                 Throw up       0.49      0.67      0.57        51\n",
            "               Throw down       0.89      0.78      0.83        51\n",
            "               Throw left       0.80      0.71      0.75        51\n",
            "              Throw right       0.80      0.71      0.76        52\n",
            "               Open twice       0.78      0.76      0.77        51\n",
            "                  Zoom in       0.66      0.76      0.70        50\n",
            "                 Zoom out       0.69      0.55      0.61        49\n",
            "\n",
            "                 accuracy                           0.67       536\n",
            "                macro avg       0.70      0.67      0.68       536\n",
            "             weighted avg       0.69      0.67      0.67       536\n",
            "\n",
            "Neural Network\n",
            "Learning Rate : 0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.1780 - loss: 2.2694 - val_accuracy: 0.3411 - val_loss: 2.0568\n",
            "Epoch 2/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.4212 - loss: 1.9199 - val_accuracy: 0.5184 - val_loss: 1.6335\n",
            "Epoch 3/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6051 - loss: 1.4138 - val_accuracy: 0.5920 - val_loss: 1.3705\n",
            "Epoch 4/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6960 - loss: 1.1026 - val_accuracy: 0.6522 - val_loss: 1.2568\n",
            "Epoch 5/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7534 - loss: 0.8719 - val_accuracy: 0.6890 - val_loss: 1.1655\n",
            "Epoch 6/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8059 - loss: 0.7091 - val_accuracy: 0.7057 - val_loss: 1.1478\n",
            "Epoch 7/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8404 - loss: 0.5855 - val_accuracy: 0.7124 - val_loss: 1.1258\n",
            "Epoch 8/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8921 - loss: 0.4662 - val_accuracy: 0.6689 - val_loss: 1.1632\n",
            "Epoch 9/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8830 - loss: 0.4222 - val_accuracy: 0.7023 - val_loss: 1.1646\n",
            "Epoch 10/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9069 - loss: 0.3560 - val_accuracy: 0.6823 - val_loss: 1.2114\n",
            "Epoch 11/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9374 - loss: 0.2792 - val_accuracy: 0.6722 - val_loss: 1.2480\n",
            "Epoch 12/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9362 - loss: 0.2729 - val_accuracy: 0.6856 - val_loss: 1.2786\n",
            "Train Accuracy: 87.19%\n",
            "Test Accuracy: 70.90%\n",
            "Learning Rate : 0.0001\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.0979 - loss: 2.2974 - val_accuracy: 0.1773 - val_loss: 2.2836\n",
            "Epoch 2/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2220 - loss: 2.2761 - val_accuracy: 0.2274 - val_loss: 2.2650\n",
            "Epoch 3/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.2796 - loss: 2.2540 - val_accuracy: 0.2943 - val_loss: 2.2420\n",
            "Epoch 4/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.3373 - loss: 2.2180 - val_accuracy: 0.3077 - val_loss: 2.2127\n",
            "Epoch 5/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.3726 - loss: 2.1831 - val_accuracy: 0.3311 - val_loss: 2.1767\n",
            "Epoch 6/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.3624 - loss: 2.1417 - val_accuracy: 0.3512 - val_loss: 2.1368\n",
            "Epoch 7/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4114 - loss: 2.0784 - val_accuracy: 0.3645 - val_loss: 2.0921\n",
            "Epoch 8/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4060 - loss: 2.0343 - val_accuracy: 0.4047 - val_loss: 2.0462\n",
            "Epoch 9/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4576 - loss: 1.9808 - val_accuracy: 0.4381 - val_loss: 1.9987\n",
            "Epoch 10/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4930 - loss: 1.9250 - val_accuracy: 0.4415 - val_loss: 1.9506\n",
            "Epoch 11/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5167 - loss: 1.8593 - val_accuracy: 0.4649 - val_loss: 1.8993\n",
            "Epoch 12/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5403 - loss: 1.7981 - val_accuracy: 0.4950 - val_loss: 1.8481\n",
            "Epoch 13/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6047 - loss: 1.7088 - val_accuracy: 0.5251 - val_loss: 1.7967\n",
            "Epoch 14/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5714 - loss: 1.6586 - val_accuracy: 0.5284 - val_loss: 1.7473\n",
            "Epoch 15/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5852 - loss: 1.6196 - val_accuracy: 0.5452 - val_loss: 1.6965\n",
            "Epoch 16/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6015 - loss: 1.5274 - val_accuracy: 0.5452 - val_loss: 1.6501\n",
            "Epoch 17/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6240 - loss: 1.4743 - val_accuracy: 0.5485 - val_loss: 1.6079\n",
            "Epoch 18/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6582 - loss: 1.3916 - val_accuracy: 0.5652 - val_loss: 1.5659\n",
            "Epoch 19/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6656 - loss: 1.3300 - val_accuracy: 0.5753 - val_loss: 1.5286\n",
            "Epoch 20/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6567 - loss: 1.3045 - val_accuracy: 0.5853 - val_loss: 1.4987\n",
            "Epoch 21/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6742 - loss: 1.2539 - val_accuracy: 0.5819 - val_loss: 1.4685\n",
            "Epoch 22/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6827 - loss: 1.1984 - val_accuracy: 0.5920 - val_loss: 1.4424\n",
            "Epoch 23/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7357 - loss: 1.1198 - val_accuracy: 0.6087 - val_loss: 1.4162\n",
            "Epoch 24/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7005 - loss: 1.1206 - val_accuracy: 0.6187 - val_loss: 1.3966\n",
            "Epoch 25/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7115 - loss: 1.0889 - val_accuracy: 0.6254 - val_loss: 1.3750\n",
            "Epoch 26/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7333 - loss: 1.0281 - val_accuracy: 0.6321 - val_loss: 1.3566\n",
            "Epoch 27/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7459 - loss: 1.0173 - val_accuracy: 0.6355 - val_loss: 1.3395\n",
            "Epoch 28/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7830 - loss: 0.9117 - val_accuracy: 0.6355 - val_loss: 1.3272\n",
            "Epoch 29/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7732 - loss: 0.9229 - val_accuracy: 0.6355 - val_loss: 1.3137\n",
            "Epoch 30/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7786 - loss: 0.9246 - val_accuracy: 0.6388 - val_loss: 1.3035\n",
            "Epoch 31/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7940 - loss: 0.8774 - val_accuracy: 0.6488 - val_loss: 1.2921\n",
            "Epoch 32/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7911 - loss: 0.8943 - val_accuracy: 0.6555 - val_loss: 1.2809\n",
            "Epoch 33/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7963 - loss: 0.8334 - val_accuracy: 0.6555 - val_loss: 1.2753\n",
            "Epoch 34/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8005 - loss: 0.8279 - val_accuracy: 0.6589 - val_loss: 1.2685\n",
            "Epoch 35/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7905 - loss: 0.8055 - val_accuracy: 0.6722 - val_loss: 1.2604\n",
            "Epoch 36/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8290 - loss: 0.7498 - val_accuracy: 0.6689 - val_loss: 1.2578\n",
            "Epoch 37/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8232 - loss: 0.7509 - val_accuracy: 0.6722 - val_loss: 1.2492\n",
            "Epoch 38/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8060 - loss: 0.7698 - val_accuracy: 0.6823 - val_loss: 1.2436\n",
            "Epoch 39/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8146 - loss: 0.7300 - val_accuracy: 0.6856 - val_loss: 1.2390\n",
            "Epoch 40/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8300 - loss: 0.6825 - val_accuracy: 0.6957 - val_loss: 1.2334\n",
            "Epoch 41/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8343 - loss: 0.6843 - val_accuracy: 0.6890 - val_loss: 1.2319\n",
            "Epoch 42/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8405 - loss: 0.6744 - val_accuracy: 0.6990 - val_loss: 1.2240\n",
            "Epoch 43/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8415 - loss: 0.6364 - val_accuracy: 0.7023 - val_loss: 1.2240\n",
            "Epoch 44/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8512 - loss: 0.6512 - val_accuracy: 0.7023 - val_loss: 1.2210\n",
            "Epoch 45/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8590 - loss: 0.6230 - val_accuracy: 0.7057 - val_loss: 1.2140\n",
            "Epoch 46/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8562 - loss: 0.6273 - val_accuracy: 0.7023 - val_loss: 1.2107\n",
            "Epoch 47/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8660 - loss: 0.5846 - val_accuracy: 0.7057 - val_loss: 1.2152\n",
            "Epoch 48/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8573 - loss: 0.5765 - val_accuracy: 0.7023 - val_loss: 1.2133\n",
            "Epoch 49/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8779 - loss: 0.5340 - val_accuracy: 0.7057 - val_loss: 1.2138\n",
            "Epoch 50/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8860 - loss: 0.5255 - val_accuracy: 0.6990 - val_loss: 1.2192\n",
            "Train Accuracy: 85.58%\n",
            "Test Accuracy: 68.28%\n",
            "Scaled Data\n",
            "Number of features : 3087\n",
            "SVM\n",
            "Parmeter C:  1\n",
            "Accuracy of the SVM classifier on Training set: 0.83\n",
            "Accuracy of the classifier on Testing set: 0.63\n",
            "classification Report\n",
            "                           precision    recall  f1-score   support\n",
            "\n",
            "              Non-gesture       0.47      0.69      0.56        81\n",
            " Pointing with one finger       0.91      0.63      0.74        51\n",
            "Pointing with two fingers       0.42      0.35      0.38        49\n",
            "                 Throw up       0.42      0.59      0.49        51\n",
            "               Throw down       0.93      0.73      0.81        51\n",
            "               Throw left       0.82      0.65      0.73        51\n",
            "              Throw right       0.83      0.73      0.78        52\n",
            "               Open twice       0.75      0.78      0.77        51\n",
            "                  Zoom in       0.62      0.68      0.65        50\n",
            "                 Zoom out       0.55      0.43      0.48        49\n",
            "\n",
            "                 accuracy                           0.63       536\n",
            "                macro avg       0.67      0.63      0.64       536\n",
            "             weighted avg       0.66      0.63      0.64       536\n",
            "\n",
            "Parmeter C:  10\n",
            "Accuracy of the SVM classifier on Training set: 0.98\n",
            "Accuracy of the classifier on Testing set: 0.64\n",
            "classification Report\n",
            "                           precision    recall  f1-score   support\n",
            "\n",
            "              Non-gesture       0.50      0.65      0.57        81\n",
            " Pointing with one finger       0.89      0.65      0.75        51\n",
            "Pointing with two fingers       0.42      0.31      0.35        49\n",
            "                 Throw up       0.42      0.63      0.50        51\n",
            "               Throw down       0.90      0.69      0.78        51\n",
            "               Throw left       0.80      0.78      0.79        51\n",
            "              Throw right       0.74      0.75      0.74        52\n",
            "               Open twice       0.80      0.69      0.74        51\n",
            "                  Zoom in       0.63      0.68      0.65        50\n",
            "                 Zoom out       0.66      0.55      0.60        49\n",
            "\n",
            "                 accuracy                           0.64       536\n",
            "                macro avg       0.67      0.64      0.65       536\n",
            "             weighted avg       0.67      0.64      0.64       536\n",
            "\n",
            "Neural Network\n",
            "Learning Rate : 0.001\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.1963 - loss: 2.6460 - val_accuracy: 0.5217 - val_loss: 1.6458\n",
            "Epoch 2/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5840 - loss: 1.4044 - val_accuracy: 0.5652 - val_loss: 1.5222\n",
            "Epoch 3/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6973 - loss: 1.0995 - val_accuracy: 0.6187 - val_loss: 1.5146\n",
            "Epoch 4/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7852 - loss: 0.7771 - val_accuracy: 0.6221 - val_loss: 1.5654\n",
            "Epoch 5/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8074 - loss: 0.6639 - val_accuracy: 0.6589 - val_loss: 1.3750\n",
            "Epoch 6/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8685 - loss: 0.4925 - val_accuracy: 0.6589 - val_loss: 1.4191\n",
            "Epoch 7/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8649 - loss: 0.4693 - val_accuracy: 0.6823 - val_loss: 1.5922\n",
            "Epoch 8/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8907 - loss: 0.3901 - val_accuracy: 0.6722 - val_loss: 1.7005\n",
            "Epoch 9/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9159 - loss: 0.3091 - val_accuracy: 0.6522 - val_loss: 1.6848\n",
            "Epoch 10/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9258 - loss: 0.2931 - val_accuracy: 0.6488 - val_loss: 1.8796\n",
            "Train Accuracy: 89.20%\n",
            "Test Accuracy: 68.66%\n",
            "Learning Rate : 0.0001\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.1222 - loss: 2.8901 - val_accuracy: 0.2274 - val_loss: 2.2261\n",
            "Epoch 2/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.1973 - loss: 2.2915 - val_accuracy: 0.3110 - val_loss: 2.0519\n",
            "Epoch 3/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.3159 - loss: 1.9948 - val_accuracy: 0.4047 - val_loss: 1.9490\n",
            "Epoch 4/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4375 - loss: 1.7666 - val_accuracy: 0.4281 - val_loss: 1.8594\n",
            "Epoch 5/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4751 - loss: 1.6233 - val_accuracy: 0.4649 - val_loss: 1.7922\n",
            "Epoch 6/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5041 - loss: 1.5386 - val_accuracy: 0.4950 - val_loss: 1.7237\n",
            "Epoch 7/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5993 - loss: 1.3827 - val_accuracy: 0.5518 - val_loss: 1.6606\n",
            "Epoch 8/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6589 - loss: 1.2391 - val_accuracy: 0.5652 - val_loss: 1.5979\n",
            "Epoch 9/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6867 - loss: 1.1658 - val_accuracy: 0.5719 - val_loss: 1.5737\n",
            "Epoch 10/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6952 - loss: 1.1265 - val_accuracy: 0.5953 - val_loss: 1.5193\n",
            "Epoch 11/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6932 - loss: 1.0851 - val_accuracy: 0.6120 - val_loss: 1.4806\n",
            "Epoch 12/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7657 - loss: 0.9267 - val_accuracy: 0.6254 - val_loss: 1.4436\n",
            "Epoch 13/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7555 - loss: 0.9183 - val_accuracy: 0.6455 - val_loss: 1.4218\n",
            "Epoch 14/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7704 - loss: 0.8785 - val_accuracy: 0.6388 - val_loss: 1.4125\n",
            "Epoch 15/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8050 - loss: 0.7942 - val_accuracy: 0.6388 - val_loss: 1.4064\n",
            "Epoch 16/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8033 - loss: 0.7523 - val_accuracy: 0.6522 - val_loss: 1.3768\n",
            "Epoch 17/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8316 - loss: 0.6801 - val_accuracy: 0.6589 - val_loss: 1.3642\n",
            "Epoch 18/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8443 - loss: 0.6269 - val_accuracy: 0.6656 - val_loss: 1.3508\n",
            "Epoch 19/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8426 - loss: 0.6119 - val_accuracy: 0.6555 - val_loss: 1.3279\n",
            "Epoch 20/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8601 - loss: 0.5880 - val_accuracy: 0.6555 - val_loss: 1.3271\n",
            "Epoch 21/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8913 - loss: 0.5197 - val_accuracy: 0.6622 - val_loss: 1.3106\n",
            "Epoch 22/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8742 - loss: 0.5138 - val_accuracy: 0.6555 - val_loss: 1.2941\n",
            "Epoch 23/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8629 - loss: 0.5371 - val_accuracy: 0.6722 - val_loss: 1.3024\n",
            "Epoch 24/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8844 - loss: 0.4711 - val_accuracy: 0.6656 - val_loss: 1.3055\n",
            "Epoch 25/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8833 - loss: 0.4559 - val_accuracy: 0.6689 - val_loss: 1.3027\n",
            "Epoch 26/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8977 - loss: 0.4219 - val_accuracy: 0.6589 - val_loss: 1.3026\n",
            "Epoch 27/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9209 - loss: 0.3543 - val_accuracy: 0.6656 - val_loss: 1.3034\n",
            "Train Accuracy: 88.87%\n",
            "Test Accuracy: 65.49%\n",
            "PCA Data\n",
            "Number of features : 420\n",
            "SVM\n",
            "Parmeter C:  1\n",
            "Accuracy of the SVM classifier on Training set: 0.81\n",
            "Accuracy of the classifier on Testing set: 0.63\n",
            "classification Report\n",
            "                           precision    recall  f1-score   support\n",
            "\n",
            "              Non-gesture       0.48      0.74      0.59        81\n",
            " Pointing with one finger       0.97      0.59      0.73        51\n",
            "Pointing with two fingers       0.43      0.47      0.45        49\n",
            "                 Throw up       0.47      0.43      0.45        51\n",
            "               Throw down       0.90      0.75      0.82        51\n",
            "               Throw left       0.78      0.63      0.70        51\n",
            "              Throw right       0.83      0.67      0.74        52\n",
            "               Open twice       0.76      0.80      0.78        51\n",
            "                  Zoom in       0.58      0.72      0.64        50\n",
            "                 Zoom out       0.51      0.41      0.45        49\n",
            "\n",
            "                 accuracy                           0.63       536\n",
            "                macro avg       0.67      0.62      0.63       536\n",
            "             weighted avg       0.66      0.63      0.63       536\n",
            "\n",
            "Parmeter C:  10\n",
            "Accuracy of the SVM classifier on Training set: 0.95\n",
            "Accuracy of the classifier on Testing set: 0.65\n",
            "classification Report\n",
            "                           precision    recall  f1-score   support\n",
            "\n",
            "              Non-gesture       0.50      0.70      0.58        81\n",
            " Pointing with one finger       0.91      0.63      0.74        51\n",
            "Pointing with two fingers       0.44      0.49      0.47        49\n",
            "                 Throw up       0.47      0.43      0.45        51\n",
            "               Throw down       0.91      0.76      0.83        51\n",
            "               Throw left       0.82      0.73      0.77        51\n",
            "              Throw right       0.76      0.75      0.76        52\n",
            "               Open twice       0.72      0.71      0.71        51\n",
            "                  Zoom in       0.64      0.70      0.67        50\n",
            "                 Zoom out       0.62      0.53      0.57        49\n",
            "\n",
            "                 accuracy                           0.65       536\n",
            "                macro avg       0.68      0.64      0.66       536\n",
            "             weighted avg       0.67      0.65      0.65       536\n",
            "\n",
            "Neural Network\n",
            "Learning Rate : 0.001\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.1251 - loss: 3.9597 - val_accuracy: 0.2007 - val_loss: 2.4647\n",
            "Epoch 2/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2495 - loss: 2.5685 - val_accuracy: 0.3378 - val_loss: 2.1747\n",
            "Epoch 3/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3197 - loss: 2.1826 - val_accuracy: 0.3980 - val_loss: 2.0400\n",
            "Epoch 4/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4318 - loss: 1.8630 - val_accuracy: 0.4147 - val_loss: 1.9613\n",
            "Epoch 5/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4691 - loss: 1.7201 - val_accuracy: 0.4548 - val_loss: 1.8563\n",
            "Epoch 6/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5365 - loss: 1.4414 - val_accuracy: 0.4983 - val_loss: 1.7688\n",
            "Epoch 7/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5802 - loss: 1.2841 - val_accuracy: 0.5184 - val_loss: 1.7121\n",
            "Epoch 8/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6576 - loss: 1.1430 - val_accuracy: 0.5518 - val_loss: 1.6581\n",
            "Epoch 9/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6963 - loss: 1.0445 - val_accuracy: 0.5686 - val_loss: 1.6122\n",
            "Epoch 10/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7285 - loss: 0.9361 - val_accuracy: 0.5886 - val_loss: 1.5899\n",
            "Epoch 11/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7507 - loss: 0.8928 - val_accuracy: 0.5920 - val_loss: 1.5829\n",
            "Epoch 12/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7598 - loss: 0.8296 - val_accuracy: 0.6054 - val_loss: 1.5555\n",
            "Epoch 13/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8062 - loss: 0.7012 - val_accuracy: 0.6154 - val_loss: 1.5272\n",
            "Epoch 14/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8101 - loss: 0.6799 - val_accuracy: 0.6120 - val_loss: 1.5693\n",
            "Epoch 15/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8226 - loss: 0.6484 - val_accuracy: 0.6321 - val_loss: 1.5214\n",
            "Epoch 16/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8224 - loss: 0.5712 - val_accuracy: 0.6421 - val_loss: 1.5474\n",
            "Epoch 17/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8588 - loss: 0.5131 - val_accuracy: 0.6321 - val_loss: 1.5880\n",
            "Epoch 18/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8532 - loss: 0.5056 - val_accuracy: 0.6288 - val_loss: 1.5720\n",
            "Epoch 19/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8676 - loss: 0.4575 - val_accuracy: 0.6154 - val_loss: 1.6084\n",
            "Epoch 20/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8769 - loss: 0.4253 - val_accuracy: 0.6221 - val_loss: 1.6275\n",
            "Train Accuracy: 87.19%\n",
            "Test Accuracy: 64.37%\n",
            "Learning Rate : 0.0001\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0942 - loss: 4.0643 - val_accuracy: 0.1037 - val_loss: 3.4120\n",
            "Epoch 2/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1257 - loss: 3.6604 - val_accuracy: 0.1237 - val_loss: 3.1441\n",
            "Epoch 3/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1090 - loss: 3.4705 - val_accuracy: 0.1338 - val_loss: 2.9655\n",
            "Epoch 4/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1156 - loss: 3.4123 - val_accuracy: 0.1371 - val_loss: 2.8482\n",
            "Epoch 5/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1317 - loss: 3.0609 - val_accuracy: 0.1538 - val_loss: 2.7593\n",
            "Epoch 6/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1422 - loss: 3.0179 - val_accuracy: 0.1639 - val_loss: 2.6950\n",
            "Epoch 7/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1628 - loss: 2.8864 - val_accuracy: 0.1672 - val_loss: 2.6531\n",
            "Epoch 8/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1522 - loss: 2.7970 - val_accuracy: 0.1839 - val_loss: 2.6028\n",
            "Epoch 9/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1882 - loss: 2.6276 - val_accuracy: 0.2040 - val_loss: 2.5597\n",
            "Epoch 10/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1780 - loss: 2.6947 - val_accuracy: 0.2107 - val_loss: 2.5270\n",
            "Epoch 11/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1940 - loss: 2.5543 - val_accuracy: 0.2140 - val_loss: 2.4963\n",
            "Epoch 12/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2072 - loss: 2.5055 - val_accuracy: 0.2308 - val_loss: 2.4688\n",
            "Epoch 13/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2125 - loss: 2.5237 - val_accuracy: 0.2475 - val_loss: 2.4416\n",
            "Epoch 14/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2426 - loss: 2.4397 - val_accuracy: 0.2609 - val_loss: 2.4154\n",
            "Epoch 15/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2221 - loss: 2.3848 - val_accuracy: 0.2776 - val_loss: 2.3978\n",
            "Epoch 16/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2469 - loss: 2.3910 - val_accuracy: 0.2910 - val_loss: 2.3744\n",
            "Epoch 17/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2652 - loss: 2.1922 - val_accuracy: 0.3010 - val_loss: 2.3528\n",
            "Epoch 18/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2662 - loss: 2.1960 - val_accuracy: 0.3144 - val_loss: 2.3369\n",
            "Epoch 19/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2651 - loss: 2.2722 - val_accuracy: 0.3278 - val_loss: 2.3204\n",
            "Epoch 20/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3256 - loss: 2.0866 - val_accuracy: 0.3445 - val_loss: 2.3029\n",
            "Epoch 21/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2968 - loss: 2.1210 - val_accuracy: 0.3512 - val_loss: 2.2863\n",
            "Epoch 22/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3173 - loss: 2.1020 - val_accuracy: 0.3478 - val_loss: 2.2677\n",
            "Epoch 23/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3379 - loss: 2.0985 - val_accuracy: 0.3612 - val_loss: 2.2572\n",
            "Epoch 24/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3339 - loss: 2.0759 - val_accuracy: 0.3746 - val_loss: 2.2466\n",
            "Epoch 25/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3413 - loss: 1.9773 - val_accuracy: 0.3779 - val_loss: 2.2340\n",
            "Epoch 26/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3318 - loss: 1.9353 - val_accuracy: 0.3846 - val_loss: 2.2214\n",
            "Epoch 27/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3730 - loss: 1.8977 - val_accuracy: 0.3880 - val_loss: 2.2047\n",
            "Epoch 28/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4176 - loss: 1.8384 - val_accuracy: 0.3913 - val_loss: 2.1943\n",
            "Epoch 29/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3756 - loss: 1.8736 - val_accuracy: 0.3913 - val_loss: 2.1833\n",
            "Epoch 30/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3886 - loss: 1.8904 - val_accuracy: 0.3980 - val_loss: 2.1717\n",
            "Epoch 31/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3683 - loss: 1.9428 - val_accuracy: 0.4114 - val_loss: 2.1629\n",
            "Epoch 32/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4175 - loss: 1.8078 - val_accuracy: 0.4181 - val_loss: 2.1501\n",
            "Epoch 33/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4141 - loss: 1.8582 - val_accuracy: 0.4247 - val_loss: 2.1348\n",
            "Epoch 34/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4227 - loss: 1.8230 - val_accuracy: 0.4214 - val_loss: 2.1260\n",
            "Epoch 35/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4674 - loss: 1.7229 - val_accuracy: 0.4247 - val_loss: 2.1137\n",
            "Epoch 36/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4694 - loss: 1.6729 - val_accuracy: 0.4381 - val_loss: 2.0954\n",
            "Epoch 37/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4822 - loss: 1.7214 - val_accuracy: 0.4448 - val_loss: 2.0841\n",
            "Epoch 38/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4727 - loss: 1.6422 - val_accuracy: 0.4482 - val_loss: 2.0736\n",
            "Epoch 39/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5060 - loss: 1.6812 - val_accuracy: 0.4482 - val_loss: 2.0640\n",
            "Epoch 40/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4645 - loss: 1.7129 - val_accuracy: 0.4582 - val_loss: 2.0561\n",
            "Epoch 41/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4839 - loss: 1.5975 - val_accuracy: 0.4649 - val_loss: 2.0398\n",
            "Epoch 42/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4937 - loss: 1.6337 - val_accuracy: 0.4682 - val_loss: 2.0265\n",
            "Epoch 43/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4861 - loss: 1.6411 - val_accuracy: 0.4716 - val_loss: 2.0188\n",
            "Epoch 44/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4961 - loss: 1.5915 - val_accuracy: 0.4716 - val_loss: 2.0068\n",
            "Epoch 45/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5222 - loss: 1.5970 - val_accuracy: 0.4783 - val_loss: 1.9918\n",
            "Epoch 46/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5456 - loss: 1.4512 - val_accuracy: 0.4783 - val_loss: 1.9784\n",
            "Epoch 47/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5515 - loss: 1.4941 - val_accuracy: 0.4950 - val_loss: 1.9676\n",
            "Epoch 48/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5779 - loss: 1.4025 - val_accuracy: 0.4983 - val_loss: 1.9583\n",
            "Epoch 49/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5518 - loss: 1.4271 - val_accuracy: 0.5017 - val_loss: 1.9402\n",
            "Epoch 50/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5591 - loss: 1.4189 - val_accuracy: 0.5050 - val_loss: 1.9308\n",
            "Train Accuracy: 73.64%\n",
            "Test Accuracy: 56.34%\n",
            "With trajectory features\n",
            "Number of features : 3092\n",
            "SVM\n",
            "Parmeter C:  1\n",
            "Accuracy of the SVM classifier on Training set: 0.81\n",
            "Accuracy of the classifier on Testing set: 0.60\n",
            "classification Report\n",
            "                           precision    recall  f1-score   support\n",
            "\n",
            "              Non-gesture       0.44      0.48      0.46        81\n",
            " Pointing with one finger       0.84      0.63      0.72        51\n",
            "Pointing with two fingers       0.45      0.39      0.42        49\n",
            "                 Throw up       0.45      0.57      0.50        51\n",
            "               Throw down       0.91      0.76      0.83        51\n",
            "               Throw left       0.81      0.67      0.73        51\n",
            "              Throw right       0.82      0.71      0.76        52\n",
            "               Open twice       0.79      0.75      0.77        51\n",
            "                  Zoom in       0.44      0.62      0.51        50\n",
            "                 Zoom out       0.46      0.51      0.49        49\n",
            "\n",
            "                 accuracy                           0.60       536\n",
            "                macro avg       0.64      0.61      0.62       536\n",
            "             weighted avg       0.63      0.60      0.61       536\n",
            "\n",
            "Parmeter C:  10\n",
            "Accuracy of the SVM classifier on Training set: 0.96\n",
            "Accuracy of the classifier on Testing set: 0.68\n",
            "classification Report\n",
            "                           precision    recall  f1-score   support\n",
            "\n",
            "              Non-gesture       0.54      0.63      0.58        81\n",
            " Pointing with one finger       0.85      0.69      0.76        51\n",
            "Pointing with two fingers       0.46      0.39      0.42        49\n",
            "                 Throw up       0.48      0.63      0.54        51\n",
            "               Throw down       0.93      0.80      0.86        51\n",
            "               Throw left       0.76      0.75      0.75        51\n",
            "              Throw right       0.83      0.77      0.80        52\n",
            "               Open twice       0.83      0.78      0.81        51\n",
            "                  Zoom in       0.67      0.74      0.70        50\n",
            "                 Zoom out       0.62      0.61      0.62        49\n",
            "\n",
            "                 accuracy                           0.68       536\n",
            "                macro avg       0.70      0.68      0.69       536\n",
            "             weighted avg       0.69      0.68      0.68       536\n",
            "\n",
            "Neural Network\n",
            "Learning Rate : 0.001\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.2011 - loss: 2.2513 - val_accuracy: 0.3378 - val_loss: 2.0184\n",
            "Epoch 2/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4116 - loss: 1.8681 - val_accuracy: 0.5251 - val_loss: 1.6496\n",
            "Epoch 3/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6013 - loss: 1.4353 - val_accuracy: 0.6221 - val_loss: 1.3660\n",
            "Epoch 4/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6839 - loss: 1.1324 - val_accuracy: 0.6756 - val_loss: 1.2453\n",
            "Epoch 5/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7800 - loss: 0.8376 - val_accuracy: 0.6890 - val_loss: 1.2021\n",
            "Epoch 6/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8292 - loss: 0.6704 - val_accuracy: 0.6923 - val_loss: 1.1637\n",
            "Epoch 7/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8277 - loss: 0.6328 - val_accuracy: 0.6957 - val_loss: 1.1777\n",
            "Epoch 8/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8769 - loss: 0.4660 - val_accuracy: 0.6957 - val_loss: 1.1703\n",
            "Epoch 9/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9106 - loss: 0.3511 - val_accuracy: 0.7090 - val_loss: 1.1785\n",
            "Epoch 10/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9337 - loss: 0.3092 - val_accuracy: 0.7023 - val_loss: 1.2088\n",
            "Epoch 11/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9351 - loss: 0.2566 - val_accuracy: 0.6890 - val_loss: 1.3016\n",
            "Train Accuracy: 84.84%\n",
            "Test Accuracy: 66.60%\n",
            "Learning Rate : 0.0001\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.1515 - loss: 2.3027 - val_accuracy: 0.1806 - val_loss: 2.2881\n",
            "Epoch 2/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.2232 - loss: 2.2821 - val_accuracy: 0.2308 - val_loss: 2.2718\n",
            "Epoch 3/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.2752 - loss: 2.2561 - val_accuracy: 0.2676 - val_loss: 2.2501\n",
            "Epoch 4/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.2962 - loss: 2.2275 - val_accuracy: 0.2876 - val_loss: 2.2216\n",
            "Epoch 5/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3666 - loss: 2.1823 - val_accuracy: 0.3177 - val_loss: 2.1850\n",
            "Epoch 6/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3769 - loss: 2.1499 - val_accuracy: 0.3679 - val_loss: 2.1417\n",
            "Epoch 7/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4517 - loss: 2.0886 - val_accuracy: 0.3980 - val_loss: 2.0903\n",
            "Epoch 8/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4766 - loss: 2.0226 - val_accuracy: 0.4114 - val_loss: 2.0336\n",
            "Epoch 9/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5003 - loss: 1.9734 - val_accuracy: 0.4482 - val_loss: 1.9740\n",
            "Epoch 10/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5310 - loss: 1.8654 - val_accuracy: 0.4749 - val_loss: 1.9121\n",
            "Epoch 11/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5500 - loss: 1.7969 - val_accuracy: 0.4849 - val_loss: 1.8538\n",
            "Epoch 12/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5480 - loss: 1.7290 - val_accuracy: 0.4916 - val_loss: 1.7959\n",
            "Epoch 13/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5502 - loss: 1.6695 - val_accuracy: 0.5151 - val_loss: 1.7421\n",
            "Epoch 14/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5973 - loss: 1.5794 - val_accuracy: 0.5318 - val_loss: 1.6922\n",
            "Epoch 15/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5850 - loss: 1.5206 - val_accuracy: 0.5418 - val_loss: 1.6466\n",
            "Epoch 16/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6212 - loss: 1.4497 - val_accuracy: 0.5552 - val_loss: 1.6037\n",
            "Epoch 17/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6095 - loss: 1.4230 - val_accuracy: 0.5585 - val_loss: 1.5622\n",
            "Epoch 18/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6299 - loss: 1.3681 - val_accuracy: 0.5619 - val_loss: 1.5263\n",
            "Epoch 19/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6562 - loss: 1.2704 - val_accuracy: 0.5753 - val_loss: 1.4947\n",
            "Epoch 20/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6511 - loss: 1.2910 - val_accuracy: 0.5819 - val_loss: 1.4634\n",
            "Epoch 21/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6411 - loss: 1.2244 - val_accuracy: 0.5920 - val_loss: 1.4366\n",
            "Epoch 22/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6806 - loss: 1.1714 - val_accuracy: 0.6120 - val_loss: 1.4140\n",
            "Epoch 23/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7055 - loss: 1.1080 - val_accuracy: 0.6221 - val_loss: 1.3886\n",
            "Epoch 24/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7256 - loss: 1.0648 - val_accuracy: 0.6254 - val_loss: 1.3674\n",
            "Epoch 25/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7221 - loss: 1.0298 - val_accuracy: 0.6388 - val_loss: 1.3472\n",
            "Epoch 26/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7570 - loss: 0.9600 - val_accuracy: 0.6321 - val_loss: 1.3281\n",
            "Epoch 27/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7504 - loss: 0.9462 - val_accuracy: 0.6522 - val_loss: 1.3152\n",
            "Epoch 28/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7760 - loss: 0.9292 - val_accuracy: 0.6522 - val_loss: 1.3006\n",
            "Epoch 29/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7658 - loss: 0.9086 - val_accuracy: 0.6488 - val_loss: 1.2852\n",
            "Epoch 30/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7747 - loss: 0.8751 - val_accuracy: 0.6455 - val_loss: 1.2740\n",
            "Epoch 31/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7985 - loss: 0.8325 - val_accuracy: 0.6488 - val_loss: 1.2655\n",
            "Epoch 32/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7965 - loss: 0.8404 - val_accuracy: 0.6555 - val_loss: 1.2558\n",
            "Epoch 33/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8035 - loss: 0.8228 - val_accuracy: 0.6656 - val_loss: 1.2447\n",
            "Epoch 34/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8120 - loss: 0.7871 - val_accuracy: 0.6722 - val_loss: 1.2359\n",
            "Epoch 35/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8132 - loss: 0.7541 - val_accuracy: 0.6722 - val_loss: 1.2305\n",
            "Epoch 36/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8298 - loss: 0.7429 - val_accuracy: 0.6823 - val_loss: 1.2256\n",
            "Epoch 37/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8246 - loss: 0.7190 - val_accuracy: 0.6856 - val_loss: 1.2215\n",
            "Epoch 38/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8326 - loss: 0.7128 - val_accuracy: 0.6856 - val_loss: 1.2171\n",
            "Epoch 39/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8463 - loss: 0.6412 - val_accuracy: 0.6957 - val_loss: 1.2111\n",
            "Epoch 40/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8553 - loss: 0.6342 - val_accuracy: 0.6957 - val_loss: 1.2017\n",
            "Epoch 41/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8576 - loss: 0.6398 - val_accuracy: 0.6923 - val_loss: 1.1964\n",
            "Epoch 42/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8527 - loss: 0.6547 - val_accuracy: 0.6957 - val_loss: 1.1907\n",
            "Epoch 43/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8662 - loss: 0.5791 - val_accuracy: 0.6990 - val_loss: 1.1905\n",
            "Epoch 44/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8728 - loss: 0.5957 - val_accuracy: 0.6957 - val_loss: 1.1868\n",
            "Epoch 45/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8531 - loss: 0.5975 - val_accuracy: 0.6990 - val_loss: 1.1870\n",
            "Epoch 46/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8742 - loss: 0.5539 - val_accuracy: 0.7023 - val_loss: 1.1868\n",
            "Epoch 47/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8700 - loss: 0.5514 - val_accuracy: 0.6990 - val_loss: 1.1829\n",
            "Epoch 48/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8728 - loss: 0.5624 - val_accuracy: 0.7023 - val_loss: 1.1855\n",
            "Epoch 49/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8785 - loss: 0.5373 - val_accuracy: 0.6957 - val_loss: 1.1832\n",
            "Epoch 50/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8592 - loss: 0.5342 - val_accuracy: 0.6957 - val_loss: 1.1824\n",
            "Train Accuracy: 87.12%\n",
            "Test Accuracy: 67.72%\n",
            "Scaled Data\n",
            "Number of features : 3092\n",
            "SVM\n",
            "Parmeter C:  1\n",
            "Accuracy of the SVM classifier on Training set: 0.84\n",
            "Accuracy of the classifier on Testing set: 0.63\n",
            "classification Report\n",
            "                           precision    recall  f1-score   support\n",
            "\n",
            "              Non-gesture       0.48      0.68      0.56        81\n",
            " Pointing with one finger       0.91      0.63      0.74        51\n",
            "Pointing with two fingers       0.42      0.33      0.37        49\n",
            "                 Throw up       0.42      0.61      0.50        51\n",
            "               Throw down       0.93      0.73      0.81        51\n",
            "               Throw left       0.80      0.65      0.72        51\n",
            "              Throw right       0.83      0.73      0.78        52\n",
            "               Open twice       0.75      0.78      0.77        51\n",
            "                  Zoom in       0.58      0.66      0.62        50\n",
            "                 Zoom out       0.55      0.43      0.48        49\n",
            "\n",
            "                 accuracy                           0.63       536\n",
            "                macro avg       0.67      0.62      0.63       536\n",
            "             weighted avg       0.66      0.63      0.63       536\n",
            "\n",
            "Parmeter C:  10\n",
            "Accuracy of the SVM classifier on Training set: 0.98\n",
            "Accuracy of the classifier on Testing set: 0.64\n",
            "classification Report\n",
            "                           precision    recall  f1-score   support\n",
            "\n",
            "              Non-gesture       0.50      0.69      0.58        81\n",
            " Pointing with one finger       0.91      0.63      0.74        51\n",
            "Pointing with two fingers       0.42      0.31      0.35        49\n",
            "                 Throw up       0.42      0.63      0.50        51\n",
            "               Throw down       0.90      0.71      0.79        51\n",
            "               Throw left       0.80      0.80      0.80        51\n",
            "              Throw right       0.75      0.73      0.74        52\n",
            "               Open twice       0.82      0.71      0.76        51\n",
            "                  Zoom in       0.64      0.68      0.66        50\n",
            "                 Zoom out       0.64      0.51      0.57        49\n",
            "\n",
            "                 accuracy                           0.64       536\n",
            "                macro avg       0.68      0.64      0.65       536\n",
            "             weighted avg       0.67      0.64      0.65       536\n",
            "\n",
            "Neural Network\n",
            "Learning Rate : 0.001\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.2515 - loss: 2.6010 - val_accuracy: 0.5518 - val_loss: 1.7035\n",
            "Epoch 2/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5983 - loss: 1.3488 - val_accuracy: 0.6355 - val_loss: 1.4732\n",
            "Epoch 3/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7107 - loss: 0.9942 - val_accuracy: 0.6388 - val_loss: 1.4180\n",
            "Epoch 4/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7716 - loss: 0.8015 - val_accuracy: 0.6555 - val_loss: 1.4288\n",
            "Epoch 5/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8475 - loss: 0.5717 - val_accuracy: 0.6722 - val_loss: 1.5793\n",
            "Epoch 6/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8531 - loss: 0.5091 - val_accuracy: 0.6957 - val_loss: 1.5468\n",
            "Epoch 7/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8645 - loss: 0.4493 - val_accuracy: 0.6789 - val_loss: 1.5912\n",
            "Epoch 8/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9094 - loss: 0.3712 - val_accuracy: 0.6722 - val_loss: 1.6684\n",
            "Train Accuracy: 84.17%\n",
            "Test Accuracy: 67.16%\n",
            "Learning Rate : 0.0001\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.1009 - loss: 2.8929 - val_accuracy: 0.2642 - val_loss: 2.2479\n",
            "Epoch 2/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.2041 - loss: 2.3188 - val_accuracy: 0.4013 - val_loss: 2.0483\n",
            "Epoch 3/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.3441 - loss: 1.9916 - val_accuracy: 0.4448 - val_loss: 1.9390\n",
            "Epoch 4/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4239 - loss: 1.7757 - val_accuracy: 0.4682 - val_loss: 1.8589\n",
            "Epoch 5/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5123 - loss: 1.5596 - val_accuracy: 0.5217 - val_loss: 1.7948\n",
            "Epoch 6/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5212 - loss: 1.4938 - val_accuracy: 0.5284 - val_loss: 1.7273\n",
            "Epoch 7/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6007 - loss: 1.3265 - val_accuracy: 0.5585 - val_loss: 1.6834\n",
            "Epoch 8/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.6471 - loss: 1.2435 - val_accuracy: 0.5518 - val_loss: 1.6318\n",
            "Epoch 9/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6888 - loss: 1.1305 - val_accuracy: 0.5853 - val_loss: 1.5854\n",
            "Epoch 10/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7165 - loss: 1.1000 - val_accuracy: 0.5920 - val_loss: 1.5595\n",
            "Epoch 11/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7447 - loss: 0.9878 - val_accuracy: 0.6020 - val_loss: 1.5505\n",
            "Epoch 12/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7650 - loss: 0.8997 - val_accuracy: 0.6388 - val_loss: 1.5241\n",
            "Epoch 13/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7897 - loss: 0.8776 - val_accuracy: 0.6355 - val_loss: 1.4938\n",
            "Epoch 14/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8003 - loss: 0.7939 - val_accuracy: 0.6388 - val_loss: 1.4860\n",
            "Epoch 15/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8047 - loss: 0.7766 - val_accuracy: 0.6421 - val_loss: 1.4784\n",
            "Epoch 16/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8270 - loss: 0.6761 - val_accuracy: 0.6555 - val_loss: 1.4732\n",
            "Epoch 17/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8335 - loss: 0.6648 - val_accuracy: 0.6388 - val_loss: 1.4837\n",
            "Epoch 18/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8488 - loss: 0.6642 - val_accuracy: 0.6388 - val_loss: 1.4690\n",
            "Epoch 19/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8722 - loss: 0.5671 - val_accuracy: 0.6421 - val_loss: 1.4569\n",
            "Epoch 20/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8563 - loss: 0.5707 - val_accuracy: 0.6421 - val_loss: 1.4375\n",
            "Epoch 21/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8714 - loss: 0.5221 - val_accuracy: 0.6421 - val_loss: 1.4345\n",
            "Epoch 22/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8952 - loss: 0.4767 - val_accuracy: 0.6455 - val_loss: 1.4363\n",
            "Epoch 23/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8780 - loss: 0.4831 - val_accuracy: 0.6488 - val_loss: 1.4417\n",
            "Epoch 24/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8981 - loss: 0.4660 - val_accuracy: 0.6589 - val_loss: 1.4196\n",
            "Epoch 25/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8947 - loss: 0.4138 - val_accuracy: 0.6689 - val_loss: 1.4429\n",
            "Epoch 26/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9086 - loss: 0.4052 - val_accuracy: 0.6488 - val_loss: 1.4399\n",
            "Epoch 27/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9247 - loss: 0.3763 - val_accuracy: 0.6589 - val_loss: 1.4429\n",
            "Epoch 28/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9319 - loss: 0.3227 - val_accuracy: 0.6589 - val_loss: 1.4449\n",
            "Epoch 29/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9241 - loss: 0.3239 - val_accuracy: 0.6555 - val_loss: 1.4631\n",
            "Train Accuracy: 89.81%\n",
            "Test Accuracy: 65.67%\n",
            "PCA Data\n",
            "Number of features : 425\n",
            "SVM\n",
            "Parmeter C:  1\n",
            "Accuracy of the SVM classifier on Training set: 0.81\n",
            "Accuracy of the classifier on Testing set: 0.64\n",
            "classification Report\n",
            "                           precision    recall  f1-score   support\n",
            "\n",
            "              Non-gesture       0.49      0.74      0.59        81\n",
            " Pointing with one finger       0.97      0.61      0.75        51\n",
            "Pointing with two fingers       0.44      0.47      0.46        49\n",
            "                 Throw up       0.46      0.43      0.44        51\n",
            "               Throw down       0.93      0.75      0.83        51\n",
            "               Throw left       0.79      0.67      0.72        51\n",
            "              Throw right       0.82      0.71      0.76        52\n",
            "               Open twice       0.76      0.80      0.78        51\n",
            "                  Zoom in       0.58      0.70      0.64        50\n",
            "                 Zoom out       0.53      0.41      0.46        49\n",
            "\n",
            "                 accuracy                           0.64       536\n",
            "                macro avg       0.68      0.63      0.64       536\n",
            "             weighted avg       0.67      0.64      0.64       536\n",
            "\n",
            "Parmeter C:  10\n",
            "Accuracy of the SVM classifier on Training set: 0.95\n",
            "Accuracy of the classifier on Testing set: 0.66\n",
            "classification Report\n",
            "                           precision    recall  f1-score   support\n",
            "\n",
            "              Non-gesture       0.55      0.73      0.63        81\n",
            " Pointing with one finger       0.89      0.65      0.75        51\n",
            "Pointing with two fingers       0.43      0.47      0.45        49\n",
            "                 Throw up       0.45      0.43      0.44        51\n",
            "               Throw down       0.88      0.75      0.81        51\n",
            "               Throw left       0.84      0.80      0.82        51\n",
            "              Throw right       0.75      0.75      0.75        52\n",
            "               Open twice       0.76      0.75      0.75        51\n",
            "                  Zoom in       0.61      0.68      0.64        50\n",
            "                 Zoom out       0.68      0.55      0.61        49\n",
            "\n",
            "                 accuracy                           0.66       536\n",
            "                macro avg       0.68      0.66      0.66       536\n",
            "             weighted avg       0.68      0.66      0.66       536\n",
            "\n",
            "Neural Network\n",
            "Learning Rate : 0.001\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1092 - loss: 3.7708 - val_accuracy: 0.2308 - val_loss: 2.3400\n",
            "Epoch 2/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1932 - loss: 2.5846 - val_accuracy: 0.3278 - val_loss: 2.0829\n",
            "Epoch 3/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3299 - loss: 2.1371 - val_accuracy: 0.4381 - val_loss: 1.9379\n",
            "Epoch 4/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4183 - loss: 1.8689 - val_accuracy: 0.4849 - val_loss: 1.8295\n",
            "Epoch 5/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5175 - loss: 1.6228 - val_accuracy: 0.5151 - val_loss: 1.7103\n",
            "Epoch 6/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5381 - loss: 1.4839 - val_accuracy: 0.5753 - val_loss: 1.6157\n",
            "Epoch 7/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5955 - loss: 1.3659 - val_accuracy: 0.5853 - val_loss: 1.5120\n",
            "Epoch 8/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6681 - loss: 1.1628 - val_accuracy: 0.6020 - val_loss: 1.4401\n",
            "Epoch 9/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6793 - loss: 1.0984 - val_accuracy: 0.6087 - val_loss: 1.3557\n",
            "Epoch 10/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7168 - loss: 0.9548 - val_accuracy: 0.6221 - val_loss: 1.3066\n",
            "Epoch 11/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7476 - loss: 0.8407 - val_accuracy: 0.6288 - val_loss: 1.3077\n",
            "Epoch 12/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7716 - loss: 0.7843 - val_accuracy: 0.6522 - val_loss: 1.2675\n",
            "Epoch 13/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7760 - loss: 0.7022 - val_accuracy: 0.6455 - val_loss: 1.2986\n",
            "Epoch 14/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7938 - loss: 0.7302 - val_accuracy: 0.6555 - val_loss: 1.2655\n",
            "Epoch 15/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8062 - loss: 0.6494 - val_accuracy: 0.6555 - val_loss: 1.2589\n",
            "Epoch 16/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8275 - loss: 0.6054 - val_accuracy: 0.6789 - val_loss: 1.2351\n",
            "Epoch 17/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8405 - loss: 0.5017 - val_accuracy: 0.6656 - val_loss: 1.2545\n",
            "Epoch 18/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8526 - loss: 0.4950 - val_accuracy: 0.6622 - val_loss: 1.2390\n",
            "Epoch 19/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8442 - loss: 0.5727 - val_accuracy: 0.6555 - val_loss: 1.3005\n",
            "Epoch 20/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8581 - loss: 0.4341 - val_accuracy: 0.6522 - val_loss: 1.2819\n",
            "Epoch 21/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8806 - loss: 0.3888 - val_accuracy: 0.6689 - val_loss: 1.3203\n",
            "Train Accuracy: 89.13%\n",
            "Test Accuracy: 67.35%\n",
            "Learning Rate : 0.0001\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.1101 - loss: 4.2732 - val_accuracy: 0.0903 - val_loss: 3.4866\n",
            "Epoch 2/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1114 - loss: 3.9896 - val_accuracy: 0.1037 - val_loss: 3.2265\n",
            "Epoch 3/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1402 - loss: 3.8395 - val_accuracy: 0.1137 - val_loss: 3.0297\n",
            "Epoch 4/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1192 - loss: 3.6862 - val_accuracy: 0.1271 - val_loss: 2.8995\n",
            "Epoch 5/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1530 - loss: 3.3830 - val_accuracy: 0.1371 - val_loss: 2.8014\n",
            "Epoch 6/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1429 - loss: 3.2778 - val_accuracy: 0.1405 - val_loss: 2.7180\n",
            "Epoch 7/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1695 - loss: 3.0978 - val_accuracy: 0.1472 - val_loss: 2.6530\n",
            "Epoch 8/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1788 - loss: 3.0427 - val_accuracy: 0.1605 - val_loss: 2.6031\n",
            "Epoch 9/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1814 - loss: 3.0559 - val_accuracy: 0.1639 - val_loss: 2.5533\n",
            "Epoch 10/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1865 - loss: 2.8139 - val_accuracy: 0.1706 - val_loss: 2.5101\n",
            "Epoch 11/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1652 - loss: 2.6712 - val_accuracy: 0.1973 - val_loss: 2.4596\n",
            "Epoch 12/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2076 - loss: 2.6936 - val_accuracy: 0.2040 - val_loss: 2.4187\n",
            "Epoch 13/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2248 - loss: 2.6399 - val_accuracy: 0.1940 - val_loss: 2.3836\n",
            "Epoch 14/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2053 - loss: 2.6081 - val_accuracy: 0.2007 - val_loss: 2.3468\n",
            "Epoch 15/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2039 - loss: 2.6366 - val_accuracy: 0.2174 - val_loss: 2.3188\n",
            "Epoch 16/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2587 - loss: 2.3206 - val_accuracy: 0.2375 - val_loss: 2.2976\n",
            "Epoch 17/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2423 - loss: 2.2992 - val_accuracy: 0.2575 - val_loss: 2.2769\n",
            "Epoch 18/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2529 - loss: 2.3383 - val_accuracy: 0.2809 - val_loss: 2.2532\n",
            "Epoch 19/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2848 - loss: 2.2837 - val_accuracy: 0.2977 - val_loss: 2.2280\n",
            "Epoch 20/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2829 - loss: 2.2001 - val_accuracy: 0.3077 - val_loss: 2.2079\n",
            "Epoch 21/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2898 - loss: 2.1469 - val_accuracy: 0.3144 - val_loss: 2.1886\n",
            "Epoch 22/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3271 - loss: 2.0448 - val_accuracy: 0.3278 - val_loss: 2.1698\n",
            "Epoch 23/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3720 - loss: 2.0355 - val_accuracy: 0.3445 - val_loss: 2.1579\n",
            "Epoch 24/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3103 - loss: 2.1603 - val_accuracy: 0.3512 - val_loss: 2.1356\n",
            "Epoch 25/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3226 - loss: 2.1073 - val_accuracy: 0.3612 - val_loss: 2.1164\n",
            "Epoch 26/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3391 - loss: 1.9539 - val_accuracy: 0.3813 - val_loss: 2.1033\n",
            "Epoch 27/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3768 - loss: 1.9837 - val_accuracy: 0.3946 - val_loss: 2.0912\n",
            "Epoch 28/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3863 - loss: 1.9011 - val_accuracy: 0.4013 - val_loss: 2.0772\n",
            "Epoch 29/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4086 - loss: 1.8053 - val_accuracy: 0.3980 - val_loss: 2.0597\n",
            "Epoch 30/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3929 - loss: 1.8341 - val_accuracy: 0.4080 - val_loss: 2.0454\n",
            "Epoch 31/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4449 - loss: 1.7728 - val_accuracy: 0.4281 - val_loss: 2.0359\n",
            "Epoch 32/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4235 - loss: 1.8439 - val_accuracy: 0.4448 - val_loss: 2.0298\n",
            "Epoch 33/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4332 - loss: 1.7755 - val_accuracy: 0.4515 - val_loss: 2.0184\n",
            "Epoch 34/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3979 - loss: 1.8134 - val_accuracy: 0.4548 - val_loss: 2.0048\n",
            "Epoch 35/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4429 - loss: 1.7814 - val_accuracy: 0.4615 - val_loss: 1.9897\n",
            "Epoch 36/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4421 - loss: 1.6850 - val_accuracy: 0.4749 - val_loss: 1.9761\n",
            "Epoch 37/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4704 - loss: 1.6453 - val_accuracy: 0.4783 - val_loss: 1.9656\n",
            "Epoch 38/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4722 - loss: 1.6359 - val_accuracy: 0.4849 - val_loss: 1.9547\n",
            "Epoch 39/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5084 - loss: 1.5625 - val_accuracy: 0.4950 - val_loss: 1.9414\n",
            "Epoch 40/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4885 - loss: 1.6644 - val_accuracy: 0.4983 - val_loss: 1.9331\n",
            "Epoch 41/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5235 - loss: 1.5590 - val_accuracy: 0.5084 - val_loss: 1.9198\n",
            "Epoch 42/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4765 - loss: 1.6610 - val_accuracy: 0.5151 - val_loss: 1.9085\n",
            "Epoch 43/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4935 - loss: 1.6958 - val_accuracy: 0.5217 - val_loss: 1.8956\n",
            "Epoch 44/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5259 - loss: 1.5077 - val_accuracy: 0.5217 - val_loss: 1.8901\n",
            "Epoch 45/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5191 - loss: 1.5693 - val_accuracy: 0.5251 - val_loss: 1.8802\n",
            "Epoch 46/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5427 - loss: 1.5037 - val_accuracy: 0.5318 - val_loss: 1.8718\n",
            "Epoch 47/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5569 - loss: 1.4678 - val_accuracy: 0.5385 - val_loss: 1.8581\n",
            "Epoch 48/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5851 - loss: 1.3935 - val_accuracy: 0.5351 - val_loss: 1.8489\n",
            "Epoch 49/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5375 - loss: 1.4645 - val_accuracy: 0.5351 - val_loss: 1.8416\n",
            "Epoch 50/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5995 - loss: 1.3683 - val_accuracy: 0.5351 - val_loss: 1.8317\n",
            "Train Accuracy: 75.99%\n",
            "Test Accuracy: 58.02%\n"
          ]
        }
      ]
    }
  ]
}